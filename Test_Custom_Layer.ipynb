{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        (None, 101, 101, 1)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPaddi (None, 129, 129, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 129, 129, 40)      400       \n",
      "_________________________________________________________________\n",
      "conv2dx_30 (Conv2DX)         (None, 129, 129, 40)      14400     \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 129, 129, 1)       361       \n",
      "_________________________________________________________________\n",
      "cropping2d_17 (Cropping2D)   (None, 101, 101, 1)       0         \n",
      "=================================================================\n",
      "Total params: 15,161\n",
      "Trainable params: 15,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7 samples, validate on 3 samples\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 106ms/step - loss: 0.2506 - val_loss: 0.2503\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.2503 - val_loss: 0.2499\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.2499 - val_loss: 0.2495\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.2495 - val_loss: 0.2492\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.2492 - val_loss: 0.2488\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.2488 - val_loss: 0.2484\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.2484 - val_loss: 0.2481\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.2481 - val_loss: 0.2477\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.2477 - val_loss: 0.2473\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.2473 - val_loss: 0.2470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa5d78da58>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from typing import NamedTuple\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Input, UpSampling2D, ZeroPadding2D, \\\n",
    "                         Cropping2D, Reshape, Layer\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from skimage.filters import gabor_kernel\n",
    "from keras.utils import conv_utils\n",
    "from keras import activations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.engine.base_layer import InputSpec\n",
    "from keras.legacy import interfaces\n",
    "import tensorflow as tf\n",
    "\n",
    "class _ConvX(Layer):\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 strides=1,\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=1,\n",
    "                 activation=None,\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(_ConvX, self).__init__(**kwargs)\n",
    "        self.rank = 2\n",
    "        self.filters = filters\n",
    "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2,\n",
    "                                                      'kernel_size')\n",
    "        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n",
    "        self.padding = conv_utils.normalize_padding(padding)\n",
    "        self.data_format = K.normalize_data_format(data_format)\n",
    "        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, 2,\n",
    "                                                        'dilation_rate')\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.input_dim = input_dim #get the number of 2D grids in the input tensor\n",
    "\n",
    "        self.kernel = self.add_weight( kernel_shape, #( self.filters, 2 ),\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "\n",
    "        self.bias = None\n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "\n",
    "        gaborKernelStackShape = list( self.kernel_size )\n",
    "        gaborKernelStackShape.append( self.input_dim ) #self.input_dim is the number of 2D grids in the input tensor\n",
    "        gaborKernelStackShape.append( self.filters ) #self.filters is the number of 2D grids in the output tensor\n",
    "        gaborKernels = np.zeros( tuple( gaborKernelStackShape ) )\n",
    "        self.gaborKernelsTensor = K.variable(value=gaborKernels, dtype=K.dtype( self.kernel ), name='gaborKernelsTensor') \n",
    "\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        zeros = np.zeros( (1,1,1,40) )\n",
    "        zerosTensor = K.variable(value=zeros, dtype=K.dtype( self.kernel ), name='zerosTensor') \n",
    "        outputs = K.conv2d(\n",
    "                inputs,\n",
    "                self.gaborKernelsTensor, \n",
    "                strides=self.strides,\n",
    "                padding=self.padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "        \n",
    "        outputs *= 1 + 0*K.conv2d(\n",
    "                zerosTensor,\n",
    "                self.kernel, \n",
    "                strides=self.strides,\n",
    "                padding=self.padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            out = self.activation(outputs)\n",
    "            return out\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            space = input_shape[1:-1]\n",
    "        elif self.data_format == 'channels_first':\n",
    "            space = input_shape[2:]\n",
    "        new_space = []\n",
    "        for i in range(len(space)):\n",
    "            new_dim = conv_utils.conv_output_length(\n",
    "                space[i],\n",
    "                self.kernel_size[i],\n",
    "                padding=self.padding,\n",
    "                stride=self.strides[i],\n",
    "                dilation=self.dilation_rate[i])\n",
    "            new_space.append(new_dim)\n",
    "        if self.data_format == 'channels_last':\n",
    "            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
    "        elif self.data_format == 'channels_first':\n",
    "            return (input_shape[0], self.filters) + tuple(new_space)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'rank': self.rank,\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'strides': self.strides,\n",
    "            'padding': self.padding,\n",
    "            'data_format': self.data_format,\n",
    "            'dilation_rate': self.dilation_rate,\n",
    "            'activation': activations.serialize(self.activation),\n",
    "            'use_bias': self.use_bias,\n",
    "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "            'activity_regularizer':\n",
    "                regularizers.serialize(self.activity_regularizer),\n",
    "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
    "        }\n",
    "        base_config = super(_ConvX, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "\n",
    "class Conv2DX(_ConvX):\n",
    "    @interfaces.legacy_conv2d_support\n",
    "    def __init__(self, filters,\n",
    "                 kernel_size,\n",
    "                 strides=(1, 1),\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1, 1),\n",
    "                 activation=None,\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(Conv2DX, self).__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Conv2DX, self).get_config()\n",
    "        config.pop('rank')\n",
    "        return config\n",
    "    \n",
    "input_layer = Input(shape=(101, 101, 1))\n",
    "encoder = ZeroPadding2D(padding=((14,14),(14,14))) ( input_layer )\n",
    "encoder = Conv2D(40, kernel_size=3, activation='relu', padding='same') ( encoder ) \n",
    "encoder = Conv2DX(40, kernel_size=3, activation='relu', padding='same') ( encoder ) \n",
    "decoder = Conv2D(1, kernel_size=3, activation='sigmoid', padding='same') ( encoder ) \n",
    "decoder = Cropping2D(cropping=((14,14),(14,14))) ( decoder )\n",
    "decoder_instance = Model(input_layer, decoder)\n",
    "decoder_instance.summary()\n",
    "\n",
    "def makeGabor( gridSize, angle, lambd, sigmaX, ratioSigmaXY, phase, func=np.cos ):\n",
    "    if not ( gridSize[0]%2 and gridSize[1]%2 ):\n",
    "        raise ValueError('makeGabor(): dimensions must be odd numbers.')\n",
    "    radius = (int(gridSize[0]/2.0), int(gridSize[1]/2.0))\n",
    "    [x, y] = np.meshgrid(range(-radius[0], radius[0]+1), range(-radius[1], radius[1]+1))\n",
    "    x1 = x * np.cos(angle) + y * np.sin(angle)\n",
    "    y1 = -x * np.sin(angle) + y * np.cos(angle)\n",
    "    return np.exp( - (x1**2 + ratioSigmaXY**2*y1**2)/(2*sigmaX**2)) * func(2*np.pi*(x1/lambd) + phase)\n",
    "\n",
    "allStructures = np.zeros(( 10, 101, 101))\n",
    "allStructures[0,:,:] = makeGabor(gridSize=(101,101), angle= 15*np.pi/180, lambd=4.0, sigmaX=2.0, ratioSigmaXY=1.0, phase=0.0, func=np.cos )\n",
    "allStructures[1,:,:] = makeGabor(gridSize=(101,101), angle= 22*np.pi/180, lambd=4.0, sigmaX=2.0, ratioSigmaXY=1.0, phase=0.0, func=np.cos )\n",
    "allStructures[2,:,:] = makeGabor(gridSize=(101,101), angle= 45*np.pi/180, lambd=4.0, sigmaX=2.0, ratioSigmaXY=1.0, phase=0.0, func=np.cos )\n",
    "allStructures[3,:,:] = makeGabor(gridSize=(101,101), angle= 60*np.pi/180, lambd=4.0, sigmaX=2.0, ratioSigmaXY=1.0, phase=0.0, func=np.cos )\n",
    "allStructures[4,:,:] = makeGabor(gridSize=(101,101), angle= 75*np.pi/180, lambd=4.0, sigmaX=2.0, ratioSigmaXY=1.0, phase=0.0, func=np.cos )\n",
    "allStructures[5,:,:] = makeGabor(gridSize=(101,101), angle= 90*np.pi/180, lambd=4.0, sigmaX=2.0, ratioSigmaXY=1.0, phase=0.0, func=np.cos )\n",
    "allStructures[6,:,:] = makeGabor(gridSize=(101,101), angle= 105*np.pi/180, lambd=4.0, sigmaX=2.0, ratioSigmaXY=1.0, phase=0.0, func=np.cos )\n",
    "allStructures[7,:,:] = makeGabor(gridSize=(101,101), angle= 120*np.pi/180, lambd=4.0, sigmaX=2.0, ratioSigmaXY=1.0, phase=0.0, func=np.cos )\n",
    "allStructures[8,:,:] = makeGabor(gridSize=(101,101), angle= 135*np.pi/180, lambd=4.0, sigmaX=2.0, ratioSigmaXY=1.0, phase=0.0, func=np.cos )\n",
    "allStructures[9,:,:] = makeGabor(gridSize=(101,101), angle= 150*np.pi/180, lambd=4.0, sigmaX=2.0, ratioSigmaXY=1.0, phase=0.0, func=np.cos )\n",
    "\n",
    "\n",
    "testStructures, testStructures, trainStructures, testStructures = \\\n",
    "      train_test_split(allStructures, allStructures, test_size=0.25, random_state=11111)\n",
    "    \n",
    "trainStructures = trainStructures.reshape(trainStructures.shape + (1,)) \n",
    "testStructures  = testStructures.reshape(testStructures.shape + (1,))\n",
    "\n",
    "decoder_instance.compile(optimizer='Adadelta', loss='mean_squared_error') \n",
    "\n",
    "decoder_instance.fit(trainStructures, trainStructures,\n",
    "                     epochs=10,\n",
    "                     batch_size=128,\n",
    "                     shuffle=True,\n",
    "                     validation_data=(testStructures, testStructures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
