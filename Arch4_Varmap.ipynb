{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import NamedTuple\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Input, UpSampling2D, ZeroPadding2D, Cropping2D, Conv2DTranspose\n",
    "from keras.layers.merge import concatenate\n",
    "import keras\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definições, inicializações e funções utilitárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The tolerance for floating pointer comparison\n",
    "epsilon = 0.000001\n",
    "\n",
    "#The complexity of the variogram models\n",
    "numberOfNestedStructures = 4\n",
    "numberOfParametersPerNestedStructure = 4 #ATTENTION: if you change this value, you must change the makeVariogramModelSurface() function accordingly\n",
    "totalNumberOfParameters = numberOfNestedStructures * numberOfParametersPerNestedStructure\n",
    "\n",
    "#The target sill for the variogram models\n",
    "sill = 0.64\n",
    "\n",
    "#The range for the longest structure allowed in the variogram models\n",
    "maxAxis = 50.0\n",
    "\n",
    "class StructureType(Enum):\n",
    "    Spheric     = 1\n",
    "    Exponential = 2\n",
    "    Gaussian    = 3\n",
    "    \n",
    "class EllipsoidParameters(NamedTuple):\n",
    "    Azimuth      : float\n",
    "    SemiMajorAxis: float\n",
    "    SemiMinorAxis: float\n",
    "\n",
    "class GridParameters(NamedTuple):\n",
    "    X0: float\n",
    "    Y0: float\n",
    "    DX: float\n",
    "    DY: float\n",
    "    NI: int\n",
    "    NJ: int\n",
    "\n",
    "def getExtent2D( gridParameters : GridParameters ) -> np.array :\n",
    "    gridCornerX = gridParameters.X0 - gridParameters.DX/2;\n",
    "    gridCornerY = gridParameters.Y0 - gridParameters.DY/2;\n",
    "    return [\n",
    "           gridCornerX,\n",
    "           gridCornerX + gridParameters.DX*gridParameters.NI,\n",
    "           gridCornerY,\n",
    "           gridCornerY + gridParameters.DY*gridParameters.NJ\n",
    "           ]\n",
    "\n",
    "def getGridParameters() -> GridParameters :\n",
    "    return GridParameters( X0=-50., Y0=-50., \n",
    "                           DX=1,    DY=1, \n",
    "                           NI=100,  NJ=100 )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função gera superfície variográfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def makeVariographicSurface( structureType       : StructureType, \n",
    "                             ellipsoidParameters : EllipsoidParameters, \n",
    "                             contribution        : float,\n",
    "                             gridParameters      : GridParameters ) -> np.array :\n",
    "   #NOTA VARIAVEIS COM [0] APARENTEMENTE DE FORMA DESNECESSARIA\n",
    "   #sem isso dá erro de tipo não reconhecido (array) ao tentar usar com o JIT do Numba.\n",
    "   #\n",
    "   #Cria o numpy.array seguindo os parâmetros do grid.\n",
    "   grid = np.zeros(( gridParameters.NI, gridParameters.NJ ));\n",
    "   #Check for null structure\n",
    "   if( contribution[0] < epsilon or \n",
    "       ellipsoidParameters.SemiMajorAxis[0] < epsilon or \n",
    "       ellipsoidParameters.SemiMinorAxis[0] < epsilon ) :\n",
    "       return grid;\n",
    "   #Obtem parâmetros geométricos\n",
    "   a = ellipsoidParameters.SemiMajorAxis;\n",
    "   b = ellipsoidParameters.SemiMinorAxis;\n",
    "   c = contribution;                                       #contribution to semivariance\n",
    "   theta = ellipsoidParameters.Azimuth/180.0 * math.pi; #azimuth\n",
    "   xc = gridParameters.X0 - gridParameters.DX/2 + gridParameters.DX*gridParameters.NI/2; #center of the grid\n",
    "   yc = gridParameters.Y0 - gridParameters.DY/2 + gridParameters.DY*gridParameters.NJ/2; #center of the grid\n",
    "   #Calcula o variograma em cada célula do grid   \n",
    "   for j in range( gridParameters.NJ ) :\n",
    "      for i in range( gridParameters.NI ) :\n",
    "         xCell = gridParameters.X0 + gridParameters.DX * i;\n",
    "         yCell = gridParameters.Y0 + gridParameters.DY * j;\n",
    "         x = (xCell - xc) * math.cos(theta[0]) - (yCell - yc) * math.sin(theta[0]);\n",
    "         y = (xCell - xc) * math.sin(theta[0]) + (yCell - yc) * math.cos(theta[0]);\n",
    "         modulusSquared = (x/a)*(x/a) + (y/b)*(y/b);\n",
    "         h = math.sqrt( modulusSquared[0] );\n",
    "         if( h >= 0. and h <= 1. ) :\n",
    "            semivariance = c * (3*h/2.-math.pow(h, 3)/2.);\n",
    "         else :\n",
    "            semivariance = c;\n",
    "         grid[i,j] = semivariance[0];\n",
    "   #retorna o grid\n",
    "   return grid;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para gerar a superfície de um modelo variográfico de 4 estruturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameters must be a linear 16-element array of floats in the following order:\n",
    "# azimuth, semi-major axis, semi-minor axis, contribution, azimuth, ...\n",
    "# for four structures.  Models with less than for structures can be specified with all-zero parameters\n",
    "def makeVariogramModelSurface( parameters : np.array ) -> np.array :\n",
    "    gridParameters = getGridParameters()\n",
    "    variogramModelSurface = np.zeros(( gridParameters.NI, gridParameters.NJ ));\n",
    "    for i in range( numberOfNestedStructures ) :\n",
    "        variogramModelSurface += \\\n",
    "            makeVariographicSurface( structureType = StructureType.Spheric, \n",
    "                                     ellipsoidParameters = EllipsoidParameters( Azimuth      =parameters[i*numberOfParametersPerNestedStructure+0], \n",
    "                                                                                SemiMajorAxis=parameters[i*numberOfParametersPerNestedStructure+1], \n",
    "                                                                                SemiMinorAxis=parameters[i*numberOfParametersPerNestedStructure+2] ), \n",
    "                                     contribution=parameters[i*numberOfParametersPerNestedStructure+3],\n",
    "                                     gridParameters = gridParameters )\n",
    "    return variogramModelSurface;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of random variogram surfaces to generate\n",
    "n = 5500\n",
    "\n",
    "#Allocate a volume for the stack of all variogram model surfaces n * 100 * 100\n",
    "allVariograms = np.zeros(( n, getGridParameters().NI, getGridParameters().NJ))\n",
    "\n",
    "#Allocate the stack of variographic parameters n * 16 * 1\n",
    "allParameters = np.zeros(( n, totalNumberOfParameters, 1))\n",
    "\n",
    "#Generate the variogram surfaces for training\n",
    "for iVariogram in range(n):\n",
    "    \n",
    "    #Radomize the azimuths (N000E through N180E)\n",
    "    az = np.random.rand(numberOfNestedStructures, 1)\n",
    "    \n",
    "    #Randomize the semi-major axes\n",
    "    a = np.random.rand(numberOfNestedStructures, 1)\n",
    "\n",
    "    #Randomize the semi-minor axes such that they are necessarily smaller than the semi-major axes\n",
    "    b = np.multiply( a, np.random.rand(numberOfNestedStructures, 1) )\n",
    "    \n",
    "    #Randomize the contributions such that they sum up to a total (variogram sill)\n",
    "    cc = np.random.rand(numberOfNestedStructures, 1) \n",
    "    cc = cc / np.sum(cc)\n",
    "    \n",
    "    #Linearize the array of variographic parameters\n",
    "    linearArrayOfParametersUnitized = np.column_stack( (az, a, b, cc) ).reshape(totalNumberOfParameters,1)\n",
    "    linearArrayOfParametersFullScale = np.column_stack( (az * 180, a*maxAxis, b*maxAxis, cc*sill) ).reshape(totalNumberOfParameters,1)\n",
    "    \n",
    "    #Make variogram surface\n",
    "    variogramModelSurface = makeVariogramModelSurface( linearArrayOfParametersFullScale );\n",
    "    \n",
    "    #Stack the variogram surface\n",
    "    allVariograms[iVariogram,:,:] = variogramModelSurface\n",
    "    \n",
    "    #Stack the linearized variographic parameters\n",
    "    allParameters[iVariogram,:,:] = linearArrayOfParametersUnitized\n",
    "\n",
    "\n",
    "#Prepare a plot area measuring 5 by 5 figures, each measuring 20x20\n",
    "fig, axs = plt.subplots(nrows=5, ncols=5, figsize=(20, 20))\n",
    "\n",
    "#Plot the first 25 variogram surfaces to check data\n",
    "iMap = int(0)\n",
    "for ax in axs.flat:\n",
    "\n",
    "    #plot the variogram surface\n",
    "    mappable = ax.imshow( allVariograms[iMap,:,:], \n",
    "                    interpolation='none',\n",
    "                    extent=getExtent2D( getGridParameters() ))\n",
    "    fig.colorbar(mappable, ax=ax)\n",
    "    ax.set_title( \"N\" + str(int(allParameters[iMap,0,0]*180)) + \"E; \" \n",
    "                      + str(int(allParameters[iMap,1,0]*maxAxis)) + \"x\"\n",
    "                      + str(int(allParameters[iMap,2,0]*maxAxis)) + \", cc = \"\n",
    "                      + str(int(100*allParameters[iMap,3,0])) + \"%\\n\" + \n",
    "                  \"N\" + str(int(allParameters[iMap,4,0]*180)) + \"E; \" \n",
    "                      + str(int(allParameters[iMap,5,0]*maxAxis)) + \"x\"\n",
    "                      + str(int(allParameters[iMap,6,0]*maxAxis)) + \", cc = \"\n",
    "                      + str(int(100*allParameters[iMap,7,0])) + \"%\\n\" + \n",
    "                  \"N\" + str(int(allParameters[iMap,8,0]*180)) + \"E; \" \n",
    "                      + str(int(allParameters[iMap,9,0]*maxAxis)) + \"x\"\n",
    "                      + str(int(allParameters[iMap,10,0]*maxAxis)) + \", cc = \"\n",
    "                      + str(int(100*allParameters[iMap,11,0])) + \"%\\n\" + \n",
    "                  \"N\" + str(int(allParameters[iMap,12,0]*180)) + \"E; \" \n",
    "                      + str(int(allParameters[iMap,13,0]*maxAxis)) + \"x\"\n",
    "                      + str(int(allParameters[iMap,14,0]*maxAxis)) + \", cc = \"\n",
    "                      + str(int(100*allParameters[iMap,15,0])) + \"%\" )\n",
    "    \n",
    "    #Increment the synthetic map index/count\n",
    "    iMap = iMap + 1\n",
    "    \n",
    "#Lay out the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar o mapa variográfico experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the input experimental variogram map from teh GEO-EAS format (has some headers to skip)\n",
    "experimentalVarmap = np.loadtxt(fname = \"../GR_TESE_ML/value_Varmap.dat\", skiprows=4)\n",
    "\n",
    "#get the desired column (with the experimental semivariances)\n",
    "experimentalVarmap = experimentalVarmap[:,0]\n",
    "\n",
    "#reshape to 2D image\n",
    "experimentalVarmap = experimentalVarmap.reshape(( getGridParameters().NI, getGridParameters().NJ ))\n",
    "\n",
    "#plot the experimental varmap\n",
    "plt.imshow( experimentalVarmap, interpolation='none', extent=getExtent2D( getGridParameters() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizar os dados de entrada\n",
    "#normalizer   = StandardScaler()\n",
    "#X_norm = normalizer.fit_transform(X)\n",
    "#ver se o normalizer traz para 0.0-1.0 mesmo\n",
    "#normalizar as superfícies teóricas e o experimental na mesma escala (max de todos os mapas + experimental)\n",
    "#colocar camadas de max/min pooling depois de cada camada convolutiva\n",
    "#ver rede LeNet dado em um dos notebooks da aula.\n",
    "\n",
    "#Dividir o conjunto total de superfícies variográficas e seus parâmetros em dois conjuntos:\n",
    "#  1) O conjunto de treinamento, para o processamento do backpropagation.\n",
    "#  2) O conjunto de teste, para aferição de métricas de acurácia da predição\n",
    "trainVariograms, testVariograms, trainParameters, testParameters = \\\n",
    "      train_test_split(allVariograms, allParameters, test_size=0.25, random_state=11111)\n",
    "    \n",
    "#Talvez tenha que rescalar os variogramas para 0.0-1.0\n",
    "\n",
    "#Compatibiliza os dados de entrada para uso no Keras, que espera tensores (matrizes de ordem maior que 2)\n",
    "#de ordem 4: # de imagens, dimensão I de cada imagem, dimensão J de cada imagem, # de canais em cada imagem\n",
    "trainVariograms = trainVariograms.reshape(trainVariograms.shape + (1,)) #(1,) significa uma tupla de um elemento\n",
    "testVariograms  = testVariograms.reshape(testVariograms.shape + (1,))\n",
    "\n",
    "#Cria a parte convolutiva da arquitetura de rede\n",
    "input_layer = Input(shape=(getGridParameters().NI, getGridParameters().NJ, 1))\n",
    "zp = ZeroPadding2D(padding=((14,14),(14,14))) ( input_layer )\n",
    "conv1 = Conv2D(10, kernel_size=3, activation='relu', padding='same') ( zp ) #camada convolutiva de 10 kernels (corresponde a 10 neurônios)\n",
    "mp1 = MaxPooling2D(pool_size=(2, 2), padding='same') ( conv1 )\n",
    "conv2 = Conv2D(20, kernel_size=3, activation='relu', padding='same') ( mp1 ) #camada convolutiva de 20 kernels (corresponde a 20 neurônios)\n",
    "mp2 = MaxPooling2D(pool_size=(2, 2), padding='same') ( conv2 )\n",
    "conv3 = Conv2D(40, kernel_size=3, activation='relu', padding='same') ( mp2 ) #camada convolutiva de 40 kernels (corresponde a 40 neurônios)\n",
    "mp3 = MaxPooling2D(pool_size=(2, 2), padding='same') ( conv3 )\n",
    "conv4 = Conv2D(80, kernel_size=3, activation='relu', padding='same') ( mp3 ) #camada convolutiva de 40 kernels (corresponde a 40 neurônios)\n",
    "mp4 = MaxPooling2D(pool_size=(2, 2)) ( conv4 )\n",
    "\n",
    "#O eixo central da rede U\n",
    "conv5 = Conv2D(160, kernel_size=3, activation='relu', padding='same') ( mp4 ) #camada convolutiva de 80 kernels (corresponde a 80 neurônios)\n",
    "\n",
    "#Cria a parte deconvolutiva da arquitetura de rede\n",
    "up6 = Conv2DTranspose(80, (3, 3), strides=(2, 2), padding='same') ( conv5 )\n",
    "up6 = concatenate([up6, conv4])  # <------------------------------------------informação vindo lá da camada conv.4\n",
    "conv6 = Conv2D(80, kernel_size=3, activation='relu', padding='same') ( up6 )\n",
    "up7 = Conv2DTranspose(40, (3, 3), strides=(2, 2), padding='same') ( conv6 )\n",
    "up7 = concatenate([up7, conv3])  # <------------------------------------------informação vindo lá da camada conv.3\n",
    "conv7 = Conv2D(40, kernel_size=3, activation='relu', padding='same') ( up7 )\n",
    "up8 = Conv2DTranspose(20, (3, 3), strides=(2, 2), padding='same') ( conv7 )\n",
    "up8 = concatenate([up8, conv2])  # <------------------------------------------informação vindo lá da camada conv.2\n",
    "conv8 = Conv2D(20, kernel_size=3, activation='relu', padding='same') ( up8 )\n",
    "up9 = Conv2DTranspose(10, (3, 3), strides=(2, 2), padding='same') ( conv8 )\n",
    "up9 = concatenate([up9, conv1])  # <------------------------------------------informação vindo lá da camada conv.1\n",
    "conv9 = Conv2D(10, kernel_size=3, activation='relu', padding='same') ( up9 )\n",
    "\n",
    "decoder = Conv2D(1, kernel_size=3, activation='sigmoid', padding='same') ( conv9 ) \n",
    "decoder = Cropping2D(cropping=((14,14),(14,14))) ( decoder )\n",
    "\n",
    "#Monta a arquitetura autoencoder U completa\n",
    "autoencoder = Model(input_layer, decoder)\n",
    "\n",
    "#Mostra o resumo da arquitetura\n",
    "autoencoder.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compila o modelo, passando o algoritmo de otimização, a métrica para a função-objetivo e a métrica para aferir a acurácia\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy') #metrics=[\"accuracy\"] não ajuda para regressões\n",
    "\n",
    "#treina a rede\n",
    "#25% do dado de entrada serão usados como conjunto de validação, ou seja, a cada passo (época),\n",
    "#a função-objetivo é avaliada usando esses dados\n",
    "#run_hist = model.fit(X, y, validation_split=0.15, epochs=20)\n",
    "#Em uma rede autoencoder, tanto entradas quanto as saídas são imagens de mesma dimensão.\n",
    "autoencoder.fit(trainVariograms, trainVariograms,\n",
    "                epochs=20,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(testVariograms, testVariograms))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teste a predição com os variogramas de teste\n",
    "decoded_imgs = autoencoder.predict( testVariograms )\n",
    "\n",
    "nFigs = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(nFigs):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, nFigs, i+1)\n",
    "    plt.imshow(testVariograms[i].reshape(getGridParameters().NI, getGridParameters().NJ))\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, nFigs, i + nFigs + 1)\n",
    "    plt.imshow(decoded_imgs[i].reshape(getGridParameters().NI, getGridParameters().NJ))\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenta fazer a reconstituição para o variograma experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearranja a imagem do varmap experimental para uma dimensionalidade esperada pelo Keras:\n",
    "#1ª dimensao: número de imagens (no caso soh uma)\n",
    "#dimensões do meio: dimensões de cada imagem\n",
    "#última dimensão: número de canais por imagem (no caso soh uma) para imagens muiltiespectrais ou RGB esse valor pode variar\n",
    "if( len(experimentalVarmap.shape) < 4 ) :\n",
    "    experimentalVarmap = experimentalVarmap.reshape((1,) + experimentalVarmap.shape + (1,))\n",
    "    \n",
    "#reconstituir o variograma experimental\n",
    "decoded_img = autoencoder.predict( experimentalVarmap )\n",
    "\n",
    "f, axarr = plt.subplots(1,2,figsize=(10, 10))\n",
    "axarr[0].imshow(experimentalVarmap.reshape(getGridParameters().NI, getGridParameters().NJ))\n",
    "axarr[0].get_xaxis().set_visible(False)\n",
    "axarr[0].get_yaxis().set_visible(False)\n",
    "axarr[1].imshow(decoded_img.reshape(getGridParameters().NI, getGridParameters().NJ))\n",
    "axarr[1].get_xaxis().set_visible(False)\n",
    "axarr[1].get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria uma nova rede, conectando uma MLP à saída da parte convolutiva da rede U."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remover da rede U toda a parte decodificadora.\n",
    "# ATENÇÃO: se modificar o número de camadas na parte decodificadora, é necessário\n",
    "#          mudar o range do loop abaixo.\n",
    "for i in range ( 1, 15 ) :\n",
    "   autoencoder.layers.pop()\n",
    "   autoencoder.layers[-1].outbound_nodes = []\n",
    "   autoencoder.outputs = [autoencoder.layers[-1].output]\n",
    "\n",
    "# Marcar as camadas atuais (já treinadas) como não treináveis (preservar os pesos aprendidos)\n",
    "# para que apenas a parte MLP seja treinada.\n",
    "for layer in autoencoder.layers[:] :\n",
    "    layer.trainable = False\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "#Monta a parte MLP da futura rede.\n",
    "mlp = autoencoder.layers[-1].output\n",
    "mlp = Flatten()( mlp )\n",
    "mlp = Dense( 400, activation='relu' )( mlp ) \n",
    "mlp = Dense( 200, activation='relu' )( mlp ) \n",
    "mlp = Dense( totalNumberOfParameters, activation='linear' )( mlp ) \n",
    "\n",
    "#Monta uma CNN composta pela parte convolutiva da rede U conectada\n",
    "#a uma MLP\n",
    "cnn_mlp = Model( autoencoder.input, mlp )\n",
    "cnn_mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treina a nova rede (somente a parte neuronial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compila o modelo, passando o algoritmo de otimização, a métrica para a função-objetivo e a métrica para aferir a acurácia\n",
    "cnn_mlp.compile(optimizer=keras.optimizers.Adam(), \n",
    "                loss=\"mean_squared_error\") #metrics=[\"accuracy\"] não ajuda para regressões\n",
    "\n",
    "#Compatibiliza as variáveis de resposta (parâmetros variográficos) para uso no Keras\n",
    "# Remover o ultimo elemento da tupla que representa a dimensionalidade do tensor das varíaveis de resposta\n",
    "my_list = list(testParameters.shape)\n",
    "my_list.pop(-1) #sei que última dimensão é 1\n",
    "testParameters = testParameters.reshape( tuple(my_list) )\n",
    "my_list = list(trainParameters.shape)\n",
    "my_list.pop(-1) #sei que última dimensão é 1\n",
    "trainParameters = trainParameters.reshape( tuple(my_list) )\n",
    "\n",
    "#treina a rede\n",
    "#20% do dado de entrada serão usados como conjunto de validação, ou seja, a cada passo (época),\n",
    "#a função-objetivo é avaliada usando esses dados\n",
    "#run_hist = model.fit(X, y, validation_split=0.15, epochs=20)\n",
    "cnn_mlp.fit(trainVariograms, trainParameters, \n",
    "                     validation_data=(testVariograms, testParameters), \n",
    "                     epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearranja a imagem do varmap experimental para uma dimensionalidade esperada pelo Keras:\n",
    "#1ª dimensao: número de imagens (no caso soh uma)\n",
    "#dimensões do meio: dimensões de cada imagem\n",
    "#última dimensão: número de canais por imagem (no caso soh uma) para imagens muiltiespectrais ou RGB esse valor pode variar\n",
    "if( len(experimentalVarmap.shape) < 4 ) :\n",
    "    experimentalVarmap = experimentalVarmap.reshape((1,) + experimentalVarmap.shape + (1,))\n",
    "    \n",
    "#realiza a regressão (predição)\n",
    "y_pred  = cnn_mlp.predict(experimentalVarmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred[0].reshape((4,4)))\n",
    "\n",
    "#converte array de float32 retornado pelo Keras para array de float64 para poder chamar a funcao compilada\n",
    "lala = np.zeros(( totalNumberOfParameters, 1))\n",
    "lala[:,:] = y_pred.reshape((totalNumberOfParameters, 1)) \n",
    "\n",
    "#de-unitize the predicted parameters to generate the variogram model surface\n",
    "for i in range( numberOfNestedStructures ) :\n",
    "    lala[i * numberOfParametersPerNestedStructure]     = lala[i * numberOfParametersPerNestedStructure]     * 180;\n",
    "    lala[i * numberOfParametersPerNestedStructure + 1] = lala[i * numberOfParametersPerNestedStructure + 1] * maxAxis;\n",
    "    lala[i * numberOfParametersPerNestedStructure + 2] = lala[i * numberOfParametersPerNestedStructure + 2] * maxAxis;\n",
    "    lala[i * numberOfParametersPerNestedStructure + 3] = lala[i * numberOfParametersPerNestedStructure + 3] * sill;\n",
    "variogramModelSurface = makeVariogramModelSurface( lala );\n",
    "\n",
    "#plota o modelo variografico obtido\n",
    "plt.imshow( variogramModelSurface, interpolation='none', extent=getExtent2D( getGridParameters() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
